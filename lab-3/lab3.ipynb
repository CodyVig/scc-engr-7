{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c7120f",
   "metadata": {},
   "source": [
    "# Lab 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282284e6",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcb3fbd",
   "metadata": {},
   "source": [
    "Here is a really long sentence from Moby Dick stored into a `str` called <b>sentence</b>. I've removed all the puncutation ('(,),',;, etc) to make this simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0175149",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I saw the teeming sea I saw daybreak and nightfall I saw the multitudes of America I saw a silvery cobweb in the center of a black pyramid I saw a splintered labyrinth it was London I saw close up unending eyes watching themselves in me as in a mirror I saw all the mirrors on earth and none of them reflected me I saw in a backyard of Soler Street the same tiles that thirty years before I'd seen in the entrance of a house in Fray Bentos I saw bunches of grapes snow tobacco lodes of metal steam I saw convex equatorial deserts and each one of their grains of sand I saw a woman in Inverness whom I shall never forget I saw her tangled hair her tall figure I saw the cancer in her breast I saw a ring of baked mud in a sidewalk where before there had been a tree I saw a summer house in Adrogué and a copy of the first English translation of Pliny — Philemon Holland's — and all at the same time saw each letter on each page as a boy I used to marvel that the letters in a closed book did not get scrambled and lost overnight I saw a sunset in Querétaro that seemed to reflect the colour of a rose in Bengal I saw my empty bedroom I saw in a closet in Alkmaar a terrestrial globe between two mirrors that multiplied it endlessly I saw horses with flowing manes on a shore of the Caspian Sea at dawn I saw the delicate bone structure of a hand I saw the survivors of a battle sending out picture postcards I saw in a showcase in Mirzapur a pack of Spanish playing cards I saw the slanting shadows of ferns on a greenhouse floor I saw tigers pistons bison tides and armies I saw all the ants on the planet I saw a Persian astrolabe I saw in the drawer of a writing table and the handwriting made me tremble unbelievable obscene detailed letters which Beatriz had written to Carlos Argentino I saw a monument I worshipped in the Chacarita cemetery I saw the rotted dust and bones that had once deliciously been Beatriz Viterbo I saw the circulation of my own dark blood I saw the coupling of love and the modification of death I saw the Aleph from every point and angle and in the Aleph I saw the earth and in the earth the Aleph and in the Aleph the earth I saw my own face and my own bowels I saw your face and I felt dizzy and wept for my eyes had seen that secret and conjectured object whose name is common to all men but which no man has looked upon — the unimaginable universe\"\n",
    "sentence = sentence.replace(\"—\", \"-\") # Replace unicode \\u2014"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39700b91",
   "metadata": {},
   "source": [
    "Using the built-in `str.split()`, we can convet this `str` to a list of `str`s for each word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f75e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split it into a list of words, each word separated by a \" \"\n",
    "list_of_words = sentence.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a22523a",
   "metadata": {},
   "source": [
    "Create a new list called `list_of_unique_words` that removes all duplicates. \n",
    "\n",
    "<i>Hint: </i> Use `set()` to cast to a set then back to a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0f1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Problem 1 goes here\n",
    "list_of_unique_words = []\n",
    "for word in list_of_words:\n",
    "    list_of_unique_words.append(word) if word not in list_of_unique_words else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4f741c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_of_words[0:10]=['I', 'saw', 'the', 'teeming', 'sea', 'I', 'saw', 'daybreak', 'and', 'nightfall']\n",
      "list_of_unique_words[0:10]=['I', 'saw', 'the', 'teeming', 'sea', 'daybreak', 'and', 'nightfall', 'multitudes', 'of']\n"
     ]
    }
   ],
   "source": [
    "# To verify `list_of_unique_words` looks correct\n",
    "print(f\"{list_of_words[0:10]=}\")\n",
    "print(f\"{list_of_unique_words[0:10]=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ac735",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dde2a2",
   "metadata": {},
   "source": [
    "Create a dictionary called <b>word_count</b>. \n",
    "* The keys will be a `str` representing each of the words seen in <b>list_of_words</b>. \n",
    "* The values will be the number of times that word is seen. \n",
    "\n",
    "Write a `for` loop to fill in this dictionary. The `for` loop can iterate through teach of the words in <b>list_of_words</b> becuase <b>list_of_words</b> is a list and is thus an <i>iterable</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdb13d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code for Problem 2 goes here\n",
    "\n",
    "# Create an empty dictionary\n",
    "word_count: dict = {}\n",
    "\n",
    "for word in list_of_words:\n",
    "    if word not in word_count:\n",
    "        word_count[word] = 1\n",
    "    else:\n",
    "        word_count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1860372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"I\": 39,\n",
      "    \"saw\": 36,\n",
      "    \"the\": 32,\n",
      "    \"teeming\": 1,\n",
      "    \"sea\": 1,\n",
      "    \"daybreak\": 1,\n",
      "    \"and\": 18,\n",
      "    \"nightfall\": 1,\n",
      "    \"multitudes\": 1,\n",
      "    \"of\": 22,\n",
      "    \"America\": 1,\n",
      "    \"a\": 27,\n",
      "    \"silvery\": 1,\n",
      "    \"cobweb\": 1,\n",
      "    \"in\": 22,\n",
      "    \"center\": 1,\n",
      "    \"black\": 1,\n",
      "    \"pyramid\": 1,\n",
      "    \"splintered\": 1,\n",
      "    \"labyrinth\": 1,\n",
      "    \"it\": 2,\n",
      "    \"was\": 1,\n",
      "    \"London\": 1,\n",
      "    \"close\": 1,\n",
      "    \"up\": 1,\n",
      "    \"unending\": 1,\n",
      "    \"eyes\": 2,\n",
      "    \"watching\": 1,\n",
      "    \"themselves\": 1,\n",
      "    \"me\": 3,\n",
      "    \"as\": 2,\n",
      "    \"mirror\": 1,\n",
      "    \"all\": 4,\n",
      "    \"mirrors\": 2,\n",
      "    \"on\": 5,\n",
      "    \"earth\": 4,\n",
      "    \"none\": 1,\n",
      "    \"them\": 1,\n",
      "    \"reflected\": 1,\n",
      "    \"backyard\": 1,\n",
      "    \"Soler\": 1,\n",
      "    \"Street\": 1,\n",
      "    \"same\": 2,\n",
      "    \"tiles\": 1,\n",
      "    \"that\": 6,\n",
      "    \"thirty\": 1,\n",
      "    \"years\": 1,\n",
      "    \"before\": 2,\n",
      "    \"I'd\": 1,\n",
      "    \"seen\": 2,\n",
      "    \"entrance\": 1,\n",
      "    \"house\": 2,\n",
      "    \"Fray\": 1,\n",
      "    \"Bentos\": 1,\n",
      "    \"bunches\": 1,\n",
      "    \"grapes\": 1,\n",
      "    \"snow\": 1,\n",
      "    \"tobacco\": 1,\n",
      "    \"lodes\": 1,\n",
      "    \"metal\": 1,\n",
      "    \"steam\": 1,\n",
      "    \"convex\": 1,\n",
      "    \"equatorial\": 1,\n",
      "    \"deserts\": 1,\n",
      "    \"each\": 3,\n",
      "    \"one\": 1,\n",
      "    \"their\": 1,\n",
      "    \"grains\": 1,\n",
      "    \"sand\": 1,\n",
      "    \"woman\": 1,\n",
      "    \"Inverness\": 1,\n",
      "    \"whom\": 1,\n",
      "    \"shall\": 1,\n",
      "    \"never\": 1,\n",
      "    \"forget\": 1,\n",
      "    \"her\": 3,\n",
      "    \"tangled\": 1,\n",
      "    \"hair\": 1,\n",
      "    \"tall\": 1,\n",
      "    \"figure\": 1,\n",
      "    \"cancer\": 1,\n",
      "    \"breast\": 1,\n",
      "    \"ring\": 1,\n",
      "    \"baked\": 1,\n",
      "    \"mud\": 1,\n",
      "    \"sidewalk\": 1,\n",
      "    \"where\": 1,\n",
      "    \"there\": 1,\n",
      "    \"had\": 4,\n",
      "    \"been\": 2,\n",
      "    \"tree\": 1,\n",
      "    \"summer\": 1,\n",
      "    \"Adrogu\\u00e9\": 1,\n",
      "    \"copy\": 1,\n",
      "    \"first\": 1,\n",
      "    \"English\": 1,\n",
      "    \"translation\": 1,\n",
      "    \"Pliny\": 1,\n",
      "    \"-\": 3,\n",
      "    \"Philemon\": 1,\n",
      "    \"Holland's\": 1,\n",
      "    \"at\": 2,\n",
      "    \"time\": 1,\n",
      "    \"letter\": 1,\n",
      "    \"page\": 1,\n",
      "    \"boy\": 1,\n",
      "    \"used\": 1,\n",
      "    \"to\": 4,\n",
      "    \"marvel\": 1,\n",
      "    \"letters\": 2,\n",
      "    \"closed\": 1,\n",
      "    \"book\": 1,\n",
      "    \"did\": 1,\n",
      "    \"not\": 1,\n",
      "    \"get\": 1,\n",
      "    \"scrambled\": 1,\n",
      "    \"lost\": 1,\n",
      "    \"overnight\": 1,\n",
      "    \"sunset\": 1,\n",
      "    \"Quer\\u00e9taro\": 1,\n",
      "    \"seemed\": 1,\n",
      "    \"reflect\": 1,\n",
      "    \"colour\": 1,\n",
      "    \"rose\": 1,\n",
      "    \"Bengal\": 1,\n",
      "    \"my\": 5,\n",
      "    \"empty\": 1,\n",
      "    \"bedroom\": 1,\n",
      "    \"closet\": 1,\n",
      "    \"Alkmaar\": 1,\n",
      "    \"terrestrial\": 1,\n",
      "    \"globe\": 1,\n",
      "    \"between\": 1,\n",
      "    \"two\": 1,\n",
      "    \"multiplied\": 1,\n",
      "    \"endlessly\": 1,\n",
      "    \"horses\": 1,\n",
      "    \"with\": 1,\n",
      "    \"flowing\": 1,\n",
      "    \"manes\": 1,\n",
      "    \"shore\": 1,\n",
      "    \"Caspian\": 1,\n",
      "    \"Sea\": 1,\n",
      "    \"dawn\": 1,\n",
      "    \"delicate\": 1,\n",
      "    \"bone\": 1,\n",
      "    \"structure\": 1,\n",
      "    \"hand\": 1,\n",
      "    \"survivors\": 1,\n",
      "    \"battle\": 1,\n",
      "    \"sending\": 1,\n",
      "    \"out\": 1,\n",
      "    \"picture\": 1,\n",
      "    \"postcards\": 1,\n",
      "    \"showcase\": 1,\n",
      "    \"Mirzapur\": 1,\n",
      "    \"pack\": 1,\n",
      "    \"Spanish\": 1,\n",
      "    \"playing\": 1,\n",
      "    \"cards\": 1,\n",
      "    \"slanting\": 1,\n",
      "    \"shadows\": 1,\n",
      "    \"ferns\": 1,\n",
      "    \"greenhouse\": 1,\n",
      "    \"floor\": 1,\n",
      "    \"tigers\": 1,\n",
      "    \"pistons\": 1,\n",
      "    \"bison\": 1,\n",
      "    \"tides\": 1,\n",
      "    \"armies\": 1,\n",
      "    \"ants\": 1,\n",
      "    \"planet\": 1,\n",
      "    \"Persian\": 1,\n",
      "    \"astrolabe\": 1,\n",
      "    \"drawer\": 1,\n",
      "    \"writing\": 1,\n",
      "    \"table\": 1,\n",
      "    \"handwriting\": 1,\n",
      "    \"made\": 1,\n",
      "    \"tremble\": 1,\n",
      "    \"unbelievable\": 1,\n",
      "    \"obscene\": 1,\n",
      "    \"detailed\": 1,\n",
      "    \"which\": 2,\n",
      "    \"Beatriz\": 2,\n",
      "    \"written\": 1,\n",
      "    \"Carlos\": 1,\n",
      "    \"Argentino\": 1,\n",
      "    \"monument\": 1,\n",
      "    \"worshipped\": 1,\n",
      "    \"Chacarita\": 1,\n",
      "    \"cemetery\": 1,\n",
      "    \"rotted\": 1,\n",
      "    \"dust\": 1,\n",
      "    \"bones\": 1,\n",
      "    \"once\": 1,\n",
      "    \"deliciously\": 1,\n",
      "    \"Viterbo\": 1,\n",
      "    \"circulation\": 1,\n",
      "    \"own\": 3,\n",
      "    \"dark\": 1,\n",
      "    \"blood\": 1,\n",
      "    \"coupling\": 1,\n",
      "    \"love\": 1,\n",
      "    \"modification\": 1,\n",
      "    \"death\": 1,\n",
      "    \"Aleph\": 4,\n",
      "    \"from\": 1,\n",
      "    \"every\": 1,\n",
      "    \"point\": 1,\n",
      "    \"angle\": 1,\n",
      "    \"face\": 2,\n",
      "    \"bowels\": 1,\n",
      "    \"your\": 1,\n",
      "    \"felt\": 1,\n",
      "    \"dizzy\": 1,\n",
      "    \"wept\": 1,\n",
      "    \"for\": 1,\n",
      "    \"secret\": 1,\n",
      "    \"conjectured\": 1,\n",
      "    \"object\": 1,\n",
      "    \"whose\": 1,\n",
      "    \"name\": 1,\n",
      "    \"is\": 1,\n",
      "    \"common\": 1,\n",
      "    \"men\": 1,\n",
      "    \"but\": 1,\n",
      "    \"no\": 1,\n",
      "    \"man\": 1,\n",
      "    \"has\": 1,\n",
      "    \"looked\": 1,\n",
      "    \"upon\": 1,\n",
      "    \"unimaginable\": 1,\n",
      "    \"universe\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from json import dumps\n",
    "\n",
    "print(dumps(word_count, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11722bca",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d11096",
   "metadata": {},
   "source": [
    "Using the  <b>sentence</b>, <b>list_of_words</b>, and <b>word_count</b> created above, write code that will determine what the most frequenty occuring word in the sentence is. Print out this word.\n",
    "\n",
    "<i> Hint: </i> You can use a for loop to go through each of the keys in word_count:\n",
    "<pre>\n",
    "for key in word_count.keys():\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a80ca724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequently occuring word is 'I' with a frequency of 39.\n"
     ]
    }
   ],
   "source": [
    "# Your code for Problem 3 goes here\n",
    "max_occuring_word = \"\"\n",
    "max_word_count = 0\n",
    "for word, frequency in word_count.items():\n",
    "    if frequency > max_word_count:\n",
    "        max_occuring_word = word\n",
    "        max_word_count = frequency\n",
    "    \n",
    "print(f\"The most frequently occuring word is '{max_occuring_word}' \"\n",
    "      + f\"with a frequency of {max_word_count}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5abce2",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d27cea",
   "metadata": {},
   "source": [
    " Create a second dicitonary called <b>word_lengths</b>:\n",
    "* The keys are ints representing the lengths of each word\n",
    "* The value of a key is the list of words that is of that length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47c7ac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"1\": [\n",
      "        \"I\",\n",
      "        \"a\",\n",
      "        \"-\"\n",
      "    ],\n",
      "    \"2\": [\n",
      "        \"of\",\n",
      "        \"in\",\n",
      "        \"it\",\n",
      "        \"up\",\n",
      "        \"me\",\n",
      "        \"as\",\n",
      "        \"on\",\n",
      "        \"at\",\n",
      "        \"to\",\n",
      "        \"my\",\n",
      "        \"is\",\n",
      "        \"no\"\n",
      "    ],\n",
      "    \"3\": [\n",
      "        \"saw\",\n",
      "        \"the\",\n",
      "        \"sea\",\n",
      "        \"and\",\n",
      "        \"was\",\n",
      "        \"all\",\n",
      "        \"I'd\",\n",
      "        \"one\",\n",
      "        \"her\",\n",
      "        \"mud\",\n",
      "        \"had\",\n",
      "        \"boy\",\n",
      "        \"did\",\n",
      "        \"not\",\n",
      "        \"get\",\n",
      "        \"two\",\n",
      "        \"Sea\",\n",
      "        \"out\",\n",
      "        \"own\",\n",
      "        \"for\",\n",
      "        \"men\",\n",
      "        \"but\",\n",
      "        \"man\",\n",
      "        \"has\"\n",
      "    ],\n",
      "    \"4\": [\n",
      "        \"eyes\",\n",
      "        \"none\",\n",
      "        \"them\",\n",
      "        \"same\",\n",
      "        \"that\",\n",
      "        \"seen\",\n",
      "        \"Fray\",\n",
      "        \"snow\",\n",
      "        \"each\",\n",
      "        \"sand\",\n",
      "        \"whom\",\n",
      "        \"hair\",\n",
      "        \"tall\",\n",
      "        \"ring\",\n",
      "        \"been\",\n",
      "        \"tree\",\n",
      "        \"copy\",\n",
      "        \"time\",\n",
      "        \"page\",\n",
      "        \"used\",\n",
      "        \"book\",\n",
      "        \"lost\",\n",
      "        \"rose\",\n",
      "        \"with\",\n",
      "        \"dawn\",\n",
      "        \"bone\",\n",
      "        \"hand\",\n",
      "        \"pack\",\n",
      "        \"ants\",\n",
      "        \"made\",\n",
      "        \"dust\",\n",
      "        \"once\",\n",
      "        \"dark\",\n",
      "        \"love\",\n",
      "        \"from\",\n",
      "        \"face\",\n",
      "        \"your\",\n",
      "        \"felt\",\n",
      "        \"wept\",\n",
      "        \"name\",\n",
      "        \"upon\"\n",
      "    ],\n",
      "    \"5\": [\n",
      "        \"black\",\n",
      "        \"close\",\n",
      "        \"earth\",\n",
      "        \"Soler\",\n",
      "        \"tiles\",\n",
      "        \"years\",\n",
      "        \"house\",\n",
      "        \"lodes\",\n",
      "        \"metal\",\n",
      "        \"steam\",\n",
      "        \"their\",\n",
      "        \"woman\",\n",
      "        \"shall\",\n",
      "        \"never\",\n",
      "        \"baked\",\n",
      "        \"where\",\n",
      "        \"there\",\n",
      "        \"first\",\n",
      "        \"Pliny\",\n",
      "        \"empty\",\n",
      "        \"globe\",\n",
      "        \"manes\",\n",
      "        \"shore\",\n",
      "        \"cards\",\n",
      "        \"ferns\",\n",
      "        \"floor\",\n",
      "        \"bison\",\n",
      "        \"tides\",\n",
      "        \"table\",\n",
      "        \"which\",\n",
      "        \"bones\",\n",
      "        \"blood\",\n",
      "        \"death\",\n",
      "        \"Aleph\",\n",
      "        \"every\",\n",
      "        \"point\",\n",
      "        \"angle\",\n",
      "        \"dizzy\",\n",
      "        \"whose\"\n",
      "    ],\n",
      "    \"6\": [\n",
      "        \"cobweb\",\n",
      "        \"center\",\n",
      "        \"London\",\n",
      "        \"mirror\",\n",
      "        \"Street\",\n",
      "        \"thirty\",\n",
      "        \"before\",\n",
      "        \"Bentos\",\n",
      "        \"grapes\",\n",
      "        \"convex\",\n",
      "        \"grains\",\n",
      "        \"forget\",\n",
      "        \"figure\",\n",
      "        \"cancer\",\n",
      "        \"breast\",\n",
      "        \"summer\",\n",
      "        \"letter\",\n",
      "        \"marvel\",\n",
      "        \"closed\",\n",
      "        \"sunset\",\n",
      "        \"seemed\",\n",
      "        \"colour\",\n",
      "        \"Bengal\",\n",
      "        \"closet\",\n",
      "        \"horses\",\n",
      "        \"battle\",\n",
      "        \"tigers\",\n",
      "        \"armies\",\n",
      "        \"planet\",\n",
      "        \"drawer\",\n",
      "        \"Carlos\",\n",
      "        \"rotted\",\n",
      "        \"bowels\",\n",
      "        \"secret\",\n",
      "        \"object\",\n",
      "        \"common\",\n",
      "        \"looked\"\n",
      "    ],\n",
      "    \"7\": [\n",
      "        \"teeming\",\n",
      "        \"America\",\n",
      "        \"silvery\",\n",
      "        \"pyramid\",\n",
      "        \"mirrors\",\n",
      "        \"bunches\",\n",
      "        \"tobacco\",\n",
      "        \"deserts\",\n",
      "        \"tangled\",\n",
      "        \"Adrogué\",\n",
      "        \"English\",\n",
      "        \"letters\",\n",
      "        \"reflect\",\n",
      "        \"bedroom\",\n",
      "        \"Alkmaar\",\n",
      "        \"between\",\n",
      "        \"flowing\",\n",
      "        \"Caspian\",\n",
      "        \"sending\",\n",
      "        \"picture\",\n",
      "        \"Spanish\",\n",
      "        \"playing\",\n",
      "        \"shadows\",\n",
      "        \"pistons\",\n",
      "        \"Persian\",\n",
      "        \"writing\",\n",
      "        \"tremble\",\n",
      "        \"obscene\",\n",
      "        \"Beatriz\",\n",
      "        \"written\",\n",
      "        \"Viterbo\"\n",
      "    ],\n",
      "    \"8\": [\n",
      "        \"daybreak\",\n",
      "        \"unending\",\n",
      "        \"watching\",\n",
      "        \"backyard\",\n",
      "        \"entrance\",\n",
      "        \"sidewalk\",\n",
      "        \"Philemon\",\n",
      "        \"delicate\",\n",
      "        \"showcase\",\n",
      "        \"Mirzapur\",\n",
      "        \"slanting\",\n",
      "        \"detailed\",\n",
      "        \"monument\",\n",
      "        \"cemetery\",\n",
      "        \"coupling\",\n",
      "        \"universe\"\n",
      "    ],\n",
      "    \"9\": [\n",
      "        \"nightfall\",\n",
      "        \"labyrinth\",\n",
      "        \"reflected\",\n",
      "        \"Inverness\",\n",
      "        \"Holland's\",\n",
      "        \"scrambled\",\n",
      "        \"overnight\",\n",
      "        \"Querétaro\",\n",
      "        \"endlessly\",\n",
      "        \"structure\",\n",
      "        \"survivors\",\n",
      "        \"postcards\",\n",
      "        \"astrolabe\",\n",
      "        \"Argentino\",\n",
      "        \"Chacarita\"\n",
      "    ],\n",
      "    \"10\": [\n",
      "        \"multitudes\",\n",
      "        \"splintered\",\n",
      "        \"themselves\",\n",
      "        \"equatorial\",\n",
      "        \"multiplied\",\n",
      "        \"greenhouse\",\n",
      "        \"worshipped\"\n",
      "    ],\n",
      "    \"11\": [\n",
      "        \"translation\",\n",
      "        \"terrestrial\",\n",
      "        \"handwriting\",\n",
      "        \"deliciously\",\n",
      "        \"circulation\",\n",
      "        \"conjectured\"\n",
      "    ],\n",
      "    \"12\": [\n",
      "        \"unbelievable\",\n",
      "        \"modification\",\n",
      "        \"unimaginable\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# your code for Problem 3 goes here\n",
    "word_lengths: dict = {}\n",
    "\n",
    "# Get the length of the longest word\n",
    "max_word_length = max([len(word) for word in list_of_unique_words])\n",
    "\n",
    "# Loop through all possible word lengths and add words of each length\n",
    "for word_length in range(1, max_word_length+1):\n",
    "    word_lengths[word_length] = [\n",
    "        word for word in list_of_unique_words if len(word) == word_length\n",
    "    ]\n",
    "\n",
    "# The encoding and decoding is to ensure `json.dumps` displays unicode correctly\n",
    "print(dumps(word_lengths, indent=4, ensure_ascii=False).encode('utf8').decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5141a698",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9afcf78",
   "metadata": {},
   "source": [
    "If we import the `random` module, we can generate random integers between 0 and 10  (including 0 and 10):\n",
    "\n",
    "<pre>\n",
    "import random\n",
    "random.randint(0,10)\n",
    "</pre>\n",
    "Here is a list of random ints. Some of the entires are lists themself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1ca10da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 1, [4, 9], [8, 8, 1], [8, 10, 6], 9, 0, 3, 9]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "lst = [random.randint(0,10), random.randint(0,10),\n",
    "    [random.randint(0,10), random.randint(0,10)],\n",
    "    [random.randint(0,10), random.randint(0,10), random.randint(0,10)],\n",
    "    [random.randint(0,10), random.randint(0,10), random.randint(0,10)],\n",
    "    random.randint(0,10),\n",
    "    random.randint(0,10),\n",
    "    random.randint(0,10), \n",
    "    random.randint(0,10)]\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1631bc1",
   "metadata": {},
   "source": [
    "Here is an example:\n",
    "<pre>\n",
    "lst = [0, 10, [0, 9], [10, 4, 2], [9, 3, 8], 0, 1, 4, 10]\n",
    "</pre>\n",
    "\n",
    "A <b>flattened</b> version of lst would look like this:\n",
    "\n",
    "<pre>\n",
    "lst_flattened = [0, 10, 0, 9, 10, 4, 2, 9, 3, 8, 0, 1, 4, 10]\n",
    "</pre>\n",
    "\n",
    "Basically the \"inner\" lists have been removed.\n",
    "\n",
    "\n",
    "Fill in the code below that will print out a flattened version of the random lst. Your code should not be specific for lst and should work on other lists of lists. \n",
    "\n",
    "<i> Hint: </i> Loop through each element in `lst` and check if it is of type `list` or not. If it is, you will need a second, inner loop. You can use the list.append() function to add an element to a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "955b87b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [random.randint(0,10), random.randint(0,10),\n",
    "    [random.randint(0,10), random.randint(0,10)],\n",
    "    [random.randint(0,10), random.randint(0,10), random.randint(0,10)],\n",
    "    [random.randint(0,10), random.randint(0,10), random.randint(0,10)],\n",
    "    random.randint(0,10),\n",
    "    random.randint(0,10),\n",
    "    random.randint(0,10), \n",
    "    random.randint(0,10)]\n",
    "\n",
    "lst_flattened = []\n",
    "\n",
    "# Your code goes here\n",
    "for element in lst:\n",
    "    if isinstance(element, list):\n",
    "        #lst_flattened.extend(elt) # Against the spirit of the problem\n",
    "        for sub_element in element:\n",
    "            lst_flattened.append(sub_element)\n",
    "    else:\n",
    "        lst_flattened.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "048476e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 6, [1, 5], [8, 3, 10], [0, 3, 6], 1, 10, 6, 8]\n",
      "[1, 6, 1, 5, 8, 3, 10, 0, 3, 6, 1, 10, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "print(lst)\n",
    "print(lst_flattened)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
